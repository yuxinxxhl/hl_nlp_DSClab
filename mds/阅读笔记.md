## TAPEX

动机：尽管预训练模型在非结构文本数据(文字)上取得了巨大成功，但是在结构化表格上仍存在挑战，原因是高质量的表格数据非常稀缺。
解决方案：通过学习**神经网络SQL执行器及其执行结果** 实现表格预训练。使用神经SQL执行器去**模拟**大规模、多样性和高质量的合成语料（对应表格数据）。
结果：在wikisql/wikitablequestions/sqa/tabfact上达到了SOTA

预训练结构化表格数据存在两个挑战：
+ 获取大规模、高质量的预训练语料
  1.爬数据 脏
  2.用表格生成数据 缺乏多样性
+ 怎样设计一个有效的针对表格的预训练任务
  MLM、Masked Column Prediction

TAPEX以一种在表格上进行形式化语言结构推理的过程解决上述问题。
首先通过抽样获得SQL查询语句，使用一个SQL执行引擎得到相应的结果，使用这些查询语句和结果来训练一个LM。

key insight：如果一个LM被训练得可以很好的“执行”SQL查询产生正确的结果，那么它应该对表格有着很深的理解。

下游任务形式：输入是由k个tokens组成的NL sentence和由N行组成的表格，每行中有多个cell，每个cell是一系列tokens以及他们对应的table header（应该是列名）。输出根据任务形式各不相同。

模型整体结构：以BART为基础

TableQA的输出是answers的链接，用逗号分隔开
TableFV的输出是以decoder最后一个token做一个二分类
将下游任务都视为一个序列生成任务

#### 预训练
常用的方法是MLM，但是需要大量语料

TAPEX的预训练任务只是adopts SQL execution

语料选取方式：1500个高质量的表格
查询抽样：在不同的表上使用SQL模板
（空结果将被丢掉

## Prompt综述

prompt基本办法：将原始输入x使用模板转换成有一些空白的文本x'，使用LM去概率性的填充这些得到x”，最后取得最终的输出y。
x ----> y    <<==>>    x----> x'----> x" ----> y
这样做的优点：
+ 可以在大量生文本上训练
+ 通过定义一种新的prompt方法，模型可以实现few-shot zero-shot学习

sea change ：预训练模型和fine-tune  / 预训练 prompt predict

#### Prompt流程

+ Prompt Addition: [x] ---- [z] ----  
+ Answer Search: 找到概率最大的Z
+ Answer Mapping：将Z与正确的输出Y做一个映射

各种任务相对应的prompt格式可以看Tab3

~~Todo:找一个特定具体的Prompt任务看一下是怎么实现的~~

#### Prompt应用(论文阅读)
Timo Schick and Hinrich Sch¨utze. 2021a. Exploiting cloze questions for few shot text classification and
natural language inference.  NLI任务 判断两个句子的相关性 感觉可以映射到表格事实检测的问题上



## TableFormer

通过一种可学习的注意力bias去更好的理解表格 

假设有位置参考，模型会更倾向于去选择训练中选择的那一行

TABLEFORMER依靠13种任务独立的table< --- >text注意力偏差 

移除了ROW/COLUMN的ids 

注意力矩阵中有不同类型的任务

## NLI应用--Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference

感觉是一种数据增强方法
- [ ] D是从哪里来的？

PVP的前提是有小规模的训练集T和一个通常很大的未标注数据集

